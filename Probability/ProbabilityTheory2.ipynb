{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conditional Probability & Total Probability Theorem**\n",
    "\n",
    "### **1. Conditional Probability**\n",
    "Conditional probability answers the question:\n",
    "\n",
    "> _\"What is the probability of event A occurring, given that event B has already occurred?\"_\n",
    "\n",
    "#### **Formula**\n",
    "$$\n",
    "P(A | B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$$\n",
    "where:\n",
    "- $ P(A | B) $ = Probability of $ A $ given $ B $\n",
    "- $ P(A \\cap B) $ = Probability of both $ A $ and $ B $ occurring\n",
    "- $ P(B) $ = Probability of $ B $ occurring\n",
    "\n",
    "#### **Example: Weather and Traffic**\n",
    "- Suppose:\n",
    "  - $ P(T) = 0.3 $ (probability of **traffic jam**)\n",
    "  - $ P(R) = 0.4 $ (probability of **rain**)\n",
    "  - $ P(T \\cap R) = 0.2 $ (probability of **traffic and rain** happening together)\n",
    "\n",
    "Now, if we know that **it’s raining**, what is the probability of traffic?\n",
    "\n",
    "$$\n",
    "P(T | R) = \\frac{P(T \\cap R)}{P(R)} = \\frac{0.2}{0.4} = 0.5\n",
    "$$\n",
    "\n",
    "So, given that it’s raining, the probability of a traffic jam increases to **50%**.\n",
    "\n",
    "### **2. Total Probability Theorem**\n",
    "The **Total Probability Theorem** helps us compute the probability of an event by considering all possible ways that event can happen.\n",
    "\n",
    "#### **Formula**\n",
    "If $ B_1, B_2, ..., B_n $ are **mutually exclusive** events that cover the entire sample space, then:\n",
    "\n",
    "$$\n",
    "P(A) = P(A | B_1) P(B_1) + P(A | B_2) P(B_2) + \\dots + P(A | B_n) P(B_n)\n",
    "$$\n",
    "\n",
    "#### **Example: Disease Testing**\n",
    "Suppose a **disease** affects people differently based on age:\n",
    "- **30%** of the population is **young** ($ B_1 $) and **70%** is **old** ($ B_2 $).\n",
    "- Probability of having the disease:\n",
    "  - **Young people**: $ P(D | B_1) = 0.01 $\n",
    "  - **Old people**: $ P(D | B_2) = 0.05 $\n",
    "\n",
    "What’s the probability that a **random person has the disease**?\n",
    "\n",
    "$$\n",
    "P(D) = P(D | B_1) P(B_1) + P(D | B_2) P(B_2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (0.01 \\times 0.3) + (0.05 \\times 0.7)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 0.003 + 0.035 = 0.038\n",
    "$$\n",
    "\n",
    "So, the overall probability of disease in the population is **3.8%**.\n",
    "\n",
    "### **Connection Between Conditional Probability & Total Probability**\n",
    "- **Conditional probability** helps compute probabilities when some information is known.\n",
    "- **Total probability** helps compute probabilities when considering all possible cases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What is Joint Probability?**  \n",
    "Joint probability refers to the probability of two (or more) random variables occurring **simultaneously**.  \n",
    "\n",
    "For two random variables $ X $ and $ Y $, the **joint probability** is denoted as:  \n",
    "\n",
    "$$\n",
    "P(X = x, Y = y)\n",
    "$$\n",
    "\n",
    "It describes the likelihood of $ X $ taking a specific value $ x $ and $ Y $ taking a specific value $ y $ **at the same time**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Joint PMF (Probability Mass Function) – Discrete Case**  \n",
    "When both $ X $ and $ Y $ are **discrete random variables**, the **Joint Probability Mass Function (Joint PMF)** is defined as:\n",
    "\n",
    "$$\n",
    "P(X = x, Y = y) = p(x, y)\n",
    "$$\n",
    "\n",
    "**Example: Joint PMF of Two Dice Rolls**  \n",
    "Consider rolling two fair dice:\n",
    "- $ X $ = outcome of the first die\n",
    "- $ Y $ = outcome of the second die  \n",
    "\n",
    "Since both dice are fair and independent:\n",
    "\n",
    "$$\n",
    "P(X = x, Y = y) = \\frac{1}{36}, \\quad x, y \\in \\{1, 2, 3, 4, 5, 6\\}\n",
    "$$\n",
    "\n",
    "**Key Property** (Sum over all possible values equals 1):\n",
    "\n",
    "$$\n",
    "\\sum_{x} \\sum_{y} P(X = x, Y = y) = 1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Joint PDF (Probability Density Function) – Continuous Case**  \n",
    "When $ X $ and $ Y $ are **continuous random variables**, the **Joint Probability Density Function (Joint PDF)** is defined as:\n",
    "\n",
    "$$\n",
    "f(x, y) \\geq 0, \\quad \\text{and} \\quad \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} f(x, y) dx dy = 1\n",
    "$$\n",
    "\n",
    "To compute the **probability over a region**, integrate the joint PDF:\n",
    "\n",
    "$$\n",
    "P(a \\leq X \\leq b, c \\leq Y \\leq d) = \\int_{a}^{b} \\int_{c}^{d} f(x, y) dx dy\n",
    "$$\n",
    "\n",
    "**Example: Joint PDF of Two Normal Variables**  \n",
    "If $ X $ and $ Y $ follow a **bivariate normal distribution**, their joint PDF is:\n",
    "\n",
    "$$\n",
    "f(x, y) = \\frac{1}{2\\pi\\sigma_X \\sigma_Y \\sqrt{1 - \\rho^2}} \\exp\\left( -\\frac{1}{2(1 - \\rho^2)} \\left( \\frac{(x - \\mu_X)^2}{\\sigma_X^2} + \\frac{(y - \\mu_Y)^2}{\\sigma_Y^2} - 2\\rho \\frac{(x - \\mu_X)(y - \\mu_Y)}{\\sigma_X \\sigma_Y} \\right) \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\mu_X, \\mu_Y $ = means of $ X $ and $ Y $,\n",
    "- $ \\sigma_X, \\sigma_Y $ = standard deviations,\n",
    "- $ \\rho $ = correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Marginal PMF and Marginal PDF**  \n",
    "Marginal probabilities describe the probability of **one** variable, regardless of the other.\n",
    "\n",
    "### **(A) Marginal PMF (Discrete Case)**\n",
    "For a discrete random variable $ X $, the **marginal PMF** is found by summing over all values of $ Y $:\n",
    "\n",
    "$$\n",
    "P(X = x) = \\sum_{y} P(X = x, Y = y)\n",
    "$$\n",
    "\n",
    "Similarly, for $ Y $:\n",
    "\n",
    "$$\n",
    "P(Y = y) = \\sum_{x} P(X = x, Y = y)\n",
    "$$\n",
    "\n",
    "**Example: Two Dice Rolls**  \n",
    "$$\n",
    "P(X = x) = \\sum_{y=1}^{6} P(X = x, Y = y) = \\sum_{y=1}^{6} \\frac{1}{36} = \\frac{6}{36} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "### **Marginal PDF (Continuous Case)**\n",
    "For a continuous random variable $ X $, the **marginal PDF** is found by integrating over all values of $ Y $:\n",
    "\n",
    "$$\n",
    "f_X(x) = \\int_{-\\infty}^{\\infty} f(x, y) dy\n",
    "$$\n",
    "\n",
    "Similarly, for $ Y $:\n",
    "\n",
    "$$\n",
    "f_Y(y) = \\int_{-\\infty}^{\\infty} f(x, y) dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Practical Applications in Machine Learning** \n",
    "\n",
    "### **(A) Feature Selection & Dimensionality Reduction**  \n",
    "- **Marginal Distributions** help analyze the **importance of individual features** in datasets.  \n",
    "- Used in **PCA (Principal Component Analysis)**, where we model the **joint distribution** of multiple features and extract marginal distributions to find independent components.\n",
    "\n",
    "### **(B) Naive Bayes Classifier**  \n",
    "- Assumes that features $ X_1, X_2, ..., X_n $ are **conditionally independent** given a class $ Y $.\n",
    "- Computes the **joint probability** as a product of **marginal probabilities**:\n",
    "\n",
    "$$\n",
    "P(Y | X_1, X_2, ..., X_n) \\propto P(Y) P(X_1 | Y) P(X_2 | Y) ... P(X_n | Y)\n",
    "$$\n",
    "\n",
    "### **(C) Generative Models (GANs, VAEs)**  \n",
    "- **VAEs (Variational Autoencoders)** model the **joint probability** of latent variables and observed data, then use **marginalization** to obtain meaningful latent representations.\n",
    "- **GANs (Generative Adversarial Networks)** learn the **joint PDF** of real and generated data.\n",
    "\n",
    "### **(D) Correlation and Dependency in Feature Engineering**  \n",
    "- **Joint PDFs** help measure **dependencies** between features.  \n",
    "- **Mutual Information** is computed from the **joint PMF/PDF** to detect **non-linear correlations**.\n",
    "\n",
    "### **(E) Bayesian Inference**  \n",
    "- Used in **Bayesian Neural Networks** and **Hidden Markov Models (HMMs)**.\n",
    "- Involves computing **posterior distributions** using joint probabilities:\n",
    "\n",
    "$$\n",
    "P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{P(X)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ P(X | \\theta) $ is the **likelihood** (joint probability of data given parameters),\n",
    "- $ P(\\theta) $ is the **prior** (initial belief),\n",
    "- $ P(X) $ is the **marginal likelihood**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
